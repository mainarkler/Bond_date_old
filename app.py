import csv
import math
import re
import time
import xml.etree.ElementTree as ET
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
from decimal import Decimal, ROUND_HALF_UP
from io import BytesIO, StringIO

import numpy as np
import pandas as pd
import requests
import sell_stress as ss
import streamlit as st
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ---------------------------
# Streamlit page setup
# ---------------------------
st.set_page_config(page_title="–†–ï–ü–û –ø—Ä–µ—Ç—Ä–µ–π–¥", page_icon="üìà", layout="wide")
st.title("üìà stat bord")

# ---------------------------
# Session state defaults
# ---------------------------
if "results" not in st.session_state:
    st.session_state["results"] = None
if "file_loaded" not in st.session_state:
    st.session_state["file_loaded"] = False
if "last_file_name" not in st.session_state:
    st.session_state["last_file_name"] = None
if "active_view" not in st.session_state:
    st.session_state["active_view"] = "home"

# ---------------------------
# Main navigation
# ---------------------------
def trigger_rerun():
    if hasattr(st, "rerun"):
        st.rerun()
    else:
        st.experimental_rerun()


if st.session_state["active_view"] != "home":
    if st.button("‚¨ÖÔ∏è –ù–∞ –≥–ª–∞–≤–Ω—É—é"):
        st.session_state["active_view"] = "home"
        trigger_rerun()

if st.session_state["active_view"] == "home":
    st.subheader("üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é")
    top_left, top_right = st.columns(2)
    with top_left:
        st.markdown("### üìà –ü—Ä–µ—Ç—Ä–µ–π–¥ –†–ï–ü–û")
        st.caption("–ê–Ω–∞–ª–∏–∑ ISIN –∏ –∫–ª—é—á–µ–≤—ã—Ö –¥–∞—Ç –±—É–º–∞–≥ –¥–ª—è —Å–¥–µ–ª–æ–∫ –†–ï–ü–û.")
        if st.button("–û—Ç–∫—Ä—ã—Ç—å", key="open_repo", use_container_width=True):
            st.session_state["active_view"] = "repo"
            trigger_rerun()
    with top_right:
        st.markdown("### üìÖ –ö–∞–ª–µ–Ω–¥–∞—Ä—å –≤—ã–ø–ª–∞—Ç")
        st.caption("–ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–∞–ª–µ–Ω–¥–∞—Ä—è –∫—É–ø–æ–Ω–æ–≤ –∏ –ø–æ–≥–∞—à–µ–Ω–∏–π.")
        if st.button("–û—Ç–∫—Ä—ã—Ç—å", key="open_calendar", use_container_width=True):
            st.session_state["active_view"] = "calendar"
            trigger_rerun()
    bottom_left, bottom_right = st.columns(2)
    with bottom_left:
        st.markdown("### üßÆ –†–∞—Å—á–µ—Ç VM")
        st.caption("–†–∞—Å—á–µ—Ç –≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ä–∂–∏ –ø–æ —Ñ—å—é—á–µ—Ä—Å–∞–º FORTS.")
        if st.button("–û—Ç–∫—Ä—ã—Ç—å", key="open_vm", use_container_width=True):
            st.session_state["active_view"] = "vm"
            trigger_rerun()
    with bottom_right:
        st.markdown("### üß© Sell_stres")
        st.caption("–û—Ü–µ–Ω–∫–∞ —Ä—ã–Ω–æ—á–Ω–æ–≥–æ –¥–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –∞–∫—Ü–∏–π –∏ –æ–±–ª–∏–≥–∞—Ü–∏–π.")
        if st.button("–û—Ç–∫—Ä—ã—Ç—å", key="open_sell_stres", use_container_width=True):
            st.session_state["active_view"] = "sell_stres"
            trigger_rerun()
    st.stop()

# ---------------------------
# HTTP session with retries
# ---------------------------
def build_http_session():
    session = requests.Session()
    retry_strategy = Retry(
        total=5,
        backoff_factor=0.8,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["GET", "POST"],
    )
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("https://", adapter)
    session.mount("http://", adapter)
    session.headers.update({"User-Agent": "python-requests/iss-moex-script"})
    return session


HTTP_SESSION = build_http_session()


def request_get(url: str, timeout: int = 15, params=None):
    response = HTTP_SESSION.get(url, timeout=timeout, params=params)
    response.raise_for_status()
    return response


# ---------------------------
# Sell_stres helpers (Share)
# ---------------------------
BASE_HISTORY_URL = (
    "https://iss.moex.com/iss/history/engines/stock/markets/shares/securities"
)


def isin_to_secid(isin: str) -> str:
    params = {"q": isin, "iss.meta": "off"}
    response = request_get("https://iss.moex.com/iss/securities.json", params=params, timeout=200)
    js = response.json()
    df = pd.DataFrame(js["securities"]["data"], columns=js["securities"]["columns"])
    df = df[df["isin"] == isin]
    if df.empty:
        raise ValueError(f"ISIN {isin} –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ MOEX")
    return df["secid"].iloc[0]


def load_moex_history(secid: str) -> pd.DataFrame:
    start = 0
    all_rows = []
    while True:
        url = f"{BASE_HISTORY_URL}/{secid}.json"
        response = request_get(url, params={"start": start}, timeout=200)
        js = response.json()
        rows = js["history"]["data"]
        cols = js["history"]["columns"]
        if not rows:
            break
        all_rows.extend(rows)
        start += len(rows)
    return pd.DataFrame(all_rows, columns=cols)


def build_q_vector(mode: str, q_max: int, q_step: int = 10_000, q_points: int = 200) -> np.ndarray:
    q_max = int(q_max)
    if q_max <= 0:
        raise ValueError("Q –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º")
    if mode == "linear":
        return np.arange(1, q_max + q_step, q_step, dtype=np.int64)
    if mode == "log":
        q = np.logspace(0, np.log10(q_max), q_points)
        return np.unique(np.round(q).astype(np.int64))
    raise ValueError("–†–µ–∂–∏–º Q –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 'linear' –∏–ª–∏ 'log'")


def calculate_share_delta_p(
    isin: str,
    c_value: float,
    date_from: str,
    q_values: np.ndarray,
) -> tuple[pd.DataFrame, dict]:
    secid = isin_to_secid(isin)
    df = load_moex_history(secid)
    df = df[["TRADEDATE", "SECID", "HIGH", "LOW", "CLOSE", "VALUE"]].copy()
    df["TRADEDATE"] = pd.to_datetime(df["TRADEDATE"])
    num_cols = ["HIGH", "LOW", "CLOSE", "VALUE"]
    df[num_cols] = df[num_cols].apply(pd.to_numeric, errors="coerce")

    date_from_dt = pd.to_datetime(date_from)
    date_to_dt = pd.to_datetime(datetime.now().date() - timedelta(days=1))
    df = df[(df["TRADEDATE"] >= date_from_dt) & (df["TRADEDATE"] <= date_to_dt)].dropna(
        subset=num_cols
    )
    if df.empty:
        raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –¥–∞—Ç–∞–º")

    df_day = (
        df.groupby(["TRADEDATE", "SECID"], as_index=False)
        .agg(
            HIGH=("HIGH", "mean"),
            LOW=("LOW", "mean"),
            CLOSE=("CLOSE", "mean"),
            VALUE=("VALUE", "sum"),
        )
        .sort_values("TRADEDATE")
    )
    t_len = len(df_day)
    if t_len == 0:
        raise ValueError("–ü—É—Å—Ç–æ–π –ø–µ—Ä–∏–æ–¥ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π")

    sigma = np.sqrt(((df_day["HIGH"] - df_day["LOW"]) / df_day["CLOSE"]).sum() / t_len)
    if not np.isfinite(sigma) or sigma <= 0:
        raise ValueError(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ œÉ = {sigma}")

    mdtv = np.median(df_day["VALUE"])
    if not np.isfinite(mdtv) or mdtv <= 0:
        raise ValueError(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π MDTV = {mdtv}")

    delta_p = c_value * sigma * np.sqrt(q_values / mdtv)
    result = pd.DataFrame({"Q": q_values, "DeltaP": delta_p})
    meta = {
        "ISIN": isin,
        "T": t_len,
        "Sigma": float(sigma),
        "MDTV": float(mdtv),
    }
    return result, meta


def generate_q(mode: str, q_max: int, points: int) -> np.ndarray:
    if q_max < 1:
        raise ValueError("Q_MAX –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å ‚â• 1")
    if points < 1:
        raise ValueError("Q_POINTS –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å ‚â• 1")
    if mode == "linear":
        return np.linspace(1, q_max, points)
    if mode == "log":
        return np.logspace(np.log10(1), np.log10(q_max), points)
    raise ValueError("Q_MODE –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 'linear' –∏–ª–∏ 'log'")


def load_bond_history(secid: str) -> pd.DataFrame:
    start = 0
    rows_all = []
    while True:
        url = (
            "https://iss.moex.com/iss/history/engines/stock/markets/bonds/securities/"
            f"{secid}.json"
        )
        response = request_get(url, params={"start": start, "iss.meta": "off"}, timeout=200)
        js = response.json()
        rows = js.get("history", {}).get("data", [])
        cols = js.get("history", {}).get("columns", [])
        if not rows:
            break
        rows_all.extend(rows)
        start += len(rows)
    return pd.DataFrame(rows_all, columns=cols)


def load_bond_yield_data(secid: str) -> pd.DataFrame:
    url = (
        "https://iss.moex.com/iss/engines/stock/markets/bonds/"
        f"securities/{secid}/marketdata_yields.json"
    )
    response = request_get(url, params={"iss.meta": "off"}, timeout=200)
    js = response.json()
    if "marketdata_yields" not in js:
        raise ValueError("–ù–µ—Ç –±–ª–æ–∫–∞ marketdata_yields")
    df = pd.DataFrame(
        js["marketdata_yields"]["data"],
        columns=js["marketdata_yields"]["columns"],
    )
    for col in ["PRICE", "DURATIONWAPRICE", "EFFECTIVEYIELDWAPRICE"]:
        df[col] = pd.to_numeric(df[col], errors="coerce")
    return df.dropna(subset=["PRICE", "DURATIONWAPRICE", "EFFECTIVEYIELDWAPRICE"])


def calculate_bond_delta_p(
    secid: str,
    c_value: float,
    date_from: str,
    date_to: str,
    q_mode: str,
    q_max: int,
    q_points: int = 50,
) -> tuple[pd.DataFrame, dict]:
    df_hist = load_bond_history(secid)
    df_yield = load_bond_yield_data(secid)
    if df_yield.empty:
        raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö marketdata_yields –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ ŒîP")

    df_hist["TRADEDATE"] = pd.to_datetime(df_hist["TRADEDATE"])
    df_hist = df_hist[
        (df_hist["TRADEDATE"] >= pd.to_datetime(date_from))
        & (df_hist["TRADEDATE"] <= pd.to_datetime(date_to))
    ]
    df_hist = df_hist[["TRADEDATE", "HIGH", "LOW", "CLOSE", "VALUE"]]
    df_hist[["HIGH", "LOW", "CLOSE", "VALUE"]] = df_hist[
        ["HIGH", "LOW", "CLOSE", "VALUE"]
    ].apply(pd.to_numeric, errors="coerce")
    df_hist = df_hist.dropna()
    if df_hist.empty:
        raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ œÉy")

    df_day = (
        df_hist.groupby("TRADEDATE", as_index=False)
        .agg({"HIGH": "mean", "LOW": "mean", "CLOSE": "mean", "VALUE": "sum"})
        .sort_values("TRADEDATE")
    )
    t_len = len(df_day)
    if t_len == 0:
        raise ValueError("–ü—É—Å—Ç–æ–π –ø–µ—Ä–∏–æ–¥ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π")

    sigma_y = ((df_day["HIGH"] - df_day["LOW"]) / df_day["CLOSE"]).sum() / t_len
    mdtv = np.median(df_day["VALUE"])
    if not np.isfinite(sigma_y) or sigma_y <= 0:
        raise ValueError("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π œÉy")
    if not np.isfinite(mdtv) or mdtv <= 0:
        raise ValueError(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π MDTV = {mdtv}")

    q_vec = generate_q(q_mode, q_max, q_points)
    delta_y = c_value * sigma_y * np.sqrt(q_vec / mdtv)

    last = df_yield.iloc[-1]
    price = float(last["PRICE"])
    ytm = float(last["EFFECTIVEYIELDWAPRICE"]) / 100
    duration = float(last["DURATIONWAPRICE"]) / 364
    dmod = duration / (1 + ytm)

    delta_p = dmod * price * delta_y
    delta_p_pct = delta_p / price

    result = pd.DataFrame({"Q": q_vec, "DeltaP_pct": delta_p_pct})
    meta = {
        "ISIN": secid,
        "T": t_len,
        "SigmaY": float(sigma_y),
        "MDTV": float(mdtv),
        "Price": price,
        "YTM": ytm,
        "Dmod": dmod,
    }
    return result, meta


def parse_number(value):
    if value is None or (isinstance(value, float) and math.isnan(value)):
        return None
    if isinstance(value, (int, float)):
        return float(value)
    try:
        cleaned = str(value).strip().replace(" ", "").replace(",", ".")
        if cleaned == "":
            return None
        return float(cleaned)
    except Exception:
        return None


def extract_secid_shortname(row):
    if isinstance(row, dict):
        secid = row.get("SECID") or row.get("secid") or ""
        shortname = row.get("SHORTNAME") or row.get("shortname") or ""
        return secid, shortname
    if isinstance(row, (list, tuple)):
        secid = row[0] if len(row) > 0 else ""
        shortname = row[1] if len(row) > 1 else ""
        return secid, shortname
    return "", ""


@st.cache_data(ttl=3600)
def fetch_forts_securities():
    url = "https://iss.moex.com/iss/engines/futures/markets/forts/securities.xml"
    params = {
        "iss.meta": "off",
        "iss.only": "securities",
        "securities.columns": "SECID,SHORTNAME",
    }
    r = request_get(url, timeout=200, params=params)
    xml_content = r.content.decode("utf-8", errors="ignore")
    xml_content = re.sub(r'\sxmlns="[^"]+"', "", xml_content, count=1)
    root = ET.fromstring(xml_content)
    rows = []
    for el in root.iter():
        if el.tag.lower().endswith("row"):
            secid = el.attrib.get("SECID") or ""
            shortname = el.attrib.get("SHORTNAME") or ""
            if secid or shortname:
                rows.append([secid, shortname])
    return rows


@st.cache_data(ttl=3600)
def fetch_forts_secid_map():
    rows = fetch_forts_securities()
    mapping = {}
    for row in rows:
        secid, shortname = extract_secid_shortname(row)
        if shortname:
            mapping[str(shortname).upper()] = secid
    return mapping


def normalize_trade_key(value: str) -> str:
    if not value:
        return ""
    normalized = re.sub(r"[^A-Z0-9]", "", str(value).upper())
    return normalized


def to_decimal(value) -> Decimal:
    return Decimal(str(value))


def money_decimal(value: Decimal) -> Decimal:
    return value.quantize(Decimal("0.01"), rounding=ROUND_HALF_UP)


@st.cache_data(ttl=3600)
def get_usd_rub_cb_today():
    url = "https://www.cbr.ru/scripts/XML_daily.asp"
    r = requests.get(url, timeout=10)
    r.raise_for_status()

    root = ET.fromstring(r.content)
    for valute in root.findall("Valute"):
        char_code = valute.findtext("CharCode")
        if char_code == "USD":
            value_str = valute.findtext("Value", "").replace(",", ".")
            nominal_str = valute.findtext("Nominal", "1")
            usd_rub = Decimal(value_str) / Decimal(nominal_str)
            usd_rub = usd_rub.quantize(Decimal("0.01"), rounding=ROUND_HALF_UP)
            return {
                "date": root.attrib.get("Date"),
                "usd_rub": usd_rub,
            }

    raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫—É—Ä—Å USD/RUB —Å –¶–ë")


def fetch_vm_data(trade_name: str, forts_rows=None):
    trade_name_clean = trade_name.strip()
    trade_name_upper = trade_name_clean.upper()
    trade_name_norm = normalize_trade_key(trade_name_clean)
    if forts_rows is None:
        forts_rows = fetch_forts_securities()
    secid_map = {}
    for row in forts_rows:
        secid, shortname = extract_secid_shortname(row)
        if shortname:
            secid_map[str(shortname).upper()] = secid
    secid = secid_map.get(trade_name_upper)
    if not secid and trade_name_norm:
        normalized_map = {
            normalize_trade_key(shortname): secid_value for shortname, secid_value in secid_map.items()
        }
        secid = normalized_map.get(trade_name_norm)
    if not secid:
        secid_match = [
            extract_secid_shortname(row)[0]
            for row in forts_rows
            if str(extract_secid_shortname(row)[0]).upper() == trade_name_upper
        ]
        if secid_match:
            secid = secid_match[0]
        else:
            partial = [
                extract_secid_shortname(row)[0]
                for row in forts_rows
                if trade_name_upper in str(extract_secid_shortname(row)[1]).upper()
            ]
            if len(partial) == 1:
                secid = partial[0]
            elif len(partial) > 1:
                raise RuntimeError(
                    f"–ù–∞–π–¥–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤ –¥–ª—è {trade_name_clean}: {', '.join(partial[:5])}"
                )
            elif trade_name_norm:
                normalized_matches = [
                    extract_secid_shortname(row)[0]
                    for row in forts_rows
                    if trade_name_norm in normalize_trade_key(extract_secid_shortname(row)[1])
                ]
                if len(normalized_matches) == 1:
                    secid = normalized_matches[0]
                elif len(normalized_matches) > 1:
                    raise RuntimeError(
                        f"–ù–∞–π–¥–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤ –¥–ª—è {trade_name_clean}: {', '.join(normalized_matches[:5])}"
                    )
    if not secid:
        raise RuntimeError(f"–ö–æ–Ω—Ç—Ä–∞–∫—Ç {trade_name_clean} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ FORTS")

    spec_url = f"https://iss.moex.com/iss/engines/futures/markets/forts/securities/{secid}.json"
    spec_params = {
        "iss.meta": "off",
        "iss.only": "securities",
        "securities.columns": "PREVSETTLEPRICE,MINSTEP,STEPPRICE,LASTSETTLEPRICE",
    }
    spec = request_get(spec_url, timeout=2000, params=spec_params).json()
    prev_settle_raw, minstep_raw, stepprice_raw, last_settle_raw = spec["securities"]["data"][0]
    prev_settle = to_decimal(prev_settle_raw)
    minstep = to_decimal(minstep_raw)
    stepprice = to_decimal(stepprice_raw)
    last_settle = to_decimal(last_settle_raw) if last_settle_raw is not None else None

    hist_url = f"https://iss.moex.com/iss/history/engines/futures/markets/forts/securities/{secid}.json"
    hist_params = {
        "iss.meta": "off",
        "iss.only": "history",
        "history.columns": "TRADEDATE,SETTLEPRICEDAY",
        "sort_order": "desc",
        "limit": 1,
    }
    history = request_get(hist_url, timeout=2000, params=hist_params).json()
    rows = history.get("history", {}).get("data", [])
    if not rows or rows[0][1] is None:
        raise RuntimeError("–î–Ω–µ–≤–Ω–æ–π –∫–ª–∏—Ä–∏–Ω–≥ –µ—â—ë –Ω–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω")

    trade_date, day_settle_raw = rows[0]
    day_settle = to_decimal(day_settle_raw)

    multiplier = stepprice / minstep
    vm = (day_settle - prev_settle) * multiplier

    return {
        "TRADE_NAME": trade_name_clean,
        "SECID": secid,
        "TRADEDATE": trade_date,
        "PREV_PRICE": float(money_decimal(prev_settle)),
        "LAST_SETTLE_PRICE": float(money_decimal(last_settle)) if last_settle is not None else None,
        "TODAY_PRICE": float(money_decimal(day_settle)),
        "MULTIPLIER": float(multiplier),
        "VM": float(money_decimal(vm)),
    }


# ---------------------------
# Safe CSV/Excel reading helpers
# ---------------------------
def safe_read_csv_string(content: str) -> pd.DataFrame:
    content = content.replace("\r\n", "\n").strip()
    sample = content[:8192]
    try:
        dialect = csv.Sniffer().sniff(sample, delimiters=[",", ";", "\t"])
        sep = dialect.delimiter
    except Exception:
        sep = ","
    try:
        df = pd.read_csv(StringIO(content), sep=sep, dtype=str)
        df.columns = [c.strip().upper() for c in df.columns]
        return df
    except Exception:
        return pd.DataFrame()


def safe_read_filelike(uploaded_file) -> pd.DataFrame:
    name = uploaded_file.name
    try:
        if name.lower().endswith(".csv"):
            raw = uploaded_file.getvalue().decode("utf-8-sig")
            return safe_read_csv_string(raw)
        return pd.read_excel(uploaded_file, dtype=str)
    except Exception:
        return pd.DataFrame()


# ---------------------------
# ISIN validation (format + checksum)
# ---------------------------
def isin_format_valid(isin: str) -> bool:
    if not isin or not isinstance(isin, str):
        return False
    return bool(re.match(r"^[A-Z]{2}[A-Z0-9]{9}[0-9]$", isin.strip().upper()))


def isin_checksum_valid(isin: str) -> bool:
    """ISIN checksum (Luhn-like). Returns True for valid ISINs."""
    if not isin_format_valid(isin):
        return False
    s = isin.strip().upper()
    converted = ""
    for ch in s[:-1]:
        if ch.isdigit():
            converted += ch
        else:
            converted += str(ord(ch) - 55)
    digits = converted + s[-1]
    arr = [int(x) for x in digits]
    total = 0
    parity = len(arr) % 2
    for i, d in enumerate(arr):
        if i % 2 == parity:
            d *= 2
            if d > 9:
                d -= 9
        total += d
    return total % 10 == 0


# ---------------------------
# Load TQOB/TQCB board XML caches (for fallback)
# ---------------------------
@st.cache_data(ttl=3600)
def fetch_board_xml(board: str):
    url = (
        "https://iss.moex.com/iss/engines/stock/markets/bonds/boards/"
        f"{board.lower()}/securities.xml?marketprice_board=3&iss.meta=off"
    )
    try:
        r = request_get(url, timeout=200)
        xml_content = r.content.decode("utf-8", errors="ignore")
        xml_content = re.sub(r'\sxmlns="[^"]+"', "", xml_content, count=1)
        root = ET.fromstring(xml_content)
        mapping = {}
        for el in root.iter():
            if el.tag.lower().endswith("row"):
                attrs = {k.upper(): v for k, v in el.attrib.items()}
                isin = attrs.get("ISIN", "").strip().upper()
                secid = attrs.get("SECID", "").strip().upper()
                emitterid = attrs.get("EMITTERID", "").strip()
                if isin:
                    mapping[isin] = {"SECID": secid or None, "EMITTERID": emitterid or None, **attrs}
        return mapping
    except Exception:
        return {}


TQOB_MAP = fetch_board_xml("tqob")
TQCB_MAP = fetch_board_xml("tqcb")

# ---------------------------
# Fetch emitter & secid (with caching)
# ---------------------------
@st.cache_data(ttl=3600)
def fetch_emitter_and_secid(isin: str):
    isin = str(isin).strip().upper()
    if not isin:
        return None, None
    emitter_id = None
    secid = None

    try:
        url = f"https://iss.moex.com/iss/securities/{isin}.json"
        r = request_get(url, timeout=10)
        data = r.json()
        securities = data.get("securities", {})
        cols = securities.get("columns", [])
        rows = securities.get("data", [])
        if rows and cols:
            first = rows[0]
            col_map = {c.upper(): i for i, c in enumerate(cols)}
            if "EMITTER_ID" in col_map:
                emitter_id = first[col_map["EMITTER_ID"]]
            elif "EMITTERID" in col_map:
                emitter_id = first[col_map["EMITTERID"]]
            if "SECID" in col_map:
                secid = first[col_map["SECID"]]
    except Exception:
        pass

    if not secid:
        try:
            url = f"https://iss.moex.com/iss/securities/{isin}.xml?iss.meta=off"
            r = request_get(url, timeout=10)
            xml_content = r.content.decode("utf-8", errors="ignore")
            xml_content = re.sub(r'\sxmlns="[^"]+"', "", xml_content, count=1)
            root = ET.fromstring(xml_content)
            for node in root.iter():
                name_attr = (node.attrib.get("name") or "").upper()
                val_attr = node.attrib.get("value") or ""
                if name_attr == "SECID":
                    secid = val_attr
                elif name_attr in ("EMITTER_ID", "EMITTERID"):
                    emitter_id = val_attr
        except Exception:
            pass

    if not secid:
        mapping = TQOB_MAP.get(isin) or TQCB_MAP.get(isin)
        if mapping:
            secid = mapping.get("SECID")
            if not emitter_id:
                emitter_id = mapping.get("EMITTERID")

    return emitter_id, secid


# ---------------------------
# Core: get bond data per ISIN
# ---------------------------
@st.cache_data(ttl=3600)
def get_bond_data(isin: str):
    isin = str(isin).strip().upper()
    try:
        emitter_id, secid = fetch_emitter_and_secid(isin)
        secname = maturity_date = put_date = call_date = None
        record_date = coupon_date = None
        coupon_currency = None
        coupon_value = None
        coupon_value_rub = None
        coupon_value_prc = None

        if secid:
            try:
                url_info = f"https://iss.moex.com/iss/engines/stock/markets/bonds/securities/{secid}.json"
                r = request_get(url_info, timeout=10)
                data_info = r.json()
                rows_info = data_info.get("securities", {}).get("data", [])
                cols_info = data_info.get("securities", {}).get("columns", [])
                if rows_info and cols_info:
                    info = dict(zip([c.upper() for c in cols_info], rows_info[0]))
                    secname = info.get("SECNAME") or info.get("SEC_NAME") or secname
                    maturity_date = info.get("MATDATE") or maturity_date
                    put_date = info.get("PUTOPTIONDATE") or put_date
                    call_date = info.get("CALLOPTIONDATE") or call_date
            except Exception:
                pass

        if not secname or not maturity_date:
            try:
                url_info_isin = f"https://iss.moex.com/iss/securities/{isin}.json"
                r = request_get(url_info_isin, timeout=10)
                data_info_isin = r.json()
                rows = data_info_isin.get("securities", {}).get("data", [])
                cols = data_info_isin.get("securities", {}).get("columns", [])
                if rows and cols:
                    info = dict(zip([c.upper() for c in cols], rows[0]))
                    secname = secname or info.get("SECNAME") or info.get("SEC_NAME")
                    maturity_date = maturity_date or info.get("MATDATE") or info.get("MATDATE")
                    put_date = put_date or info.get("PUTOPTIONDATE") or info.get("PUT_OPTION_DATE")
                    call_date = call_date or info.get("CALLOPTIONDATE") or info.get("CALL_OPTION_DATE")
            except Exception:
                pass

        coupons_data = None
        columns_coupons = []
        bondization_faceunit = None

        def try_fetch_bondization(identifier: str):
            try:
                url_coupons = (
                    "https://iss.moex.com/iss/statistics/engines/stock/markets/bonds/"
                    f"bondization/{identifier}.json?iss.only=coupons,bondization&iss.meta=off"
                )
                r = request_get(url_coupons, timeout=10)
                data = r.json()
                coupons = data.get("coupons", {}).get("data", [])
                cols = data.get("coupons", {}).get("columns", [])
                bond_rows = data.get("bondization", {}).get("data", [])
                bond_cols = data.get("bondization", {}).get("columns", [])
                faceunit = None
                if bond_rows and bond_cols:
                    bond_info = dict(zip([c.upper() for c in bond_cols], bond_rows[0]))
                    faceunit = bond_info.get("FACEUNIT") or bond_info.get("FACEUNIT_S")
                return coupons, cols, faceunit
            except Exception:
                return None, [], None

        if secid:
            coupons_data, columns_coupons, bondization_faceunit = try_fetch_bondization(secid)

        if isin and (not coupons_data or not columns_coupons):
            coupons_data_fallback, columns_coupons_fallback, bondization_faceunit_fallback = try_fetch_bondization(isin)
            if coupons_data_fallback and columns_coupons_fallback:
                coupons_data = coupons_data_fallback
                columns_coupons = columns_coupons_fallback
            if not bondization_faceunit:
                bondization_faceunit = bondization_faceunit_fallback or bondization_faceunit

        if coupons_data and columns_coupons:
            df_coupons = pd.DataFrame(coupons_data, columns=columns_coupons)
            cols_upper = [c.upper() for c in df_coupons.columns]
            df_coupons.columns = cols_upper
            today = pd.to_datetime(datetime.today().date())
            possible_coupon_date_cols = [c for c in cols_upper if "COUPON" in c and "DATE" in c]
            possible_record_date_cols = [c for c in cols_upper if "RECORD" in c and "DATE" in c]

            def next_future_date(series):
                try:
                    s = pd.to_datetime(series, errors="coerce")
                    s = s[s >= today]
                    if not s.empty:
                        return s.min().strftime("%Y-%m-%d")
                except Exception:
                    pass
                return None

            coupon_found = None
            for col in possible_coupon_date_cols:
                candidate = next_future_date(df_coupons[col])
                if candidate:
                    coupon_found = candidate
                    break
            if not coupon_found:
                all_dates = []
                for col in df_coupons.columns:
                    try:
                        s = pd.to_datetime(df_coupons[col], errors="coerce")
                        s = s[s >= today]
                        if not s.empty:
                            all_dates.append(s.min())
                    except Exception:
                        pass
                if all_dates:
                    coupon_found = min(all_dates).strftime("%Y-%m-%d")
            coupon_date = coupon_found

            record_found = None
            for col in possible_record_date_cols:
                candidate = next_future_date(df_coupons[col])
                if candidate:
                    record_found = candidate
                    break
            record_date = record_found

            if bondization_faceunit:
                coupon_currency = bondization_faceunit
            else:
                faceunit_cols = [c for c in df_coupons.columns if "FACEUNIT" in c or c == "FACEUNIT_S"]
                if faceunit_cols:
                    for c in faceunit_cols:
                        vals = df_coupons[c].dropna().astype(str)
                        if not vals.empty and vals.iloc[0].strip():
                            coupon_currency = vals.iloc[0].strip()
                            break

            val_col = None
            val_rub_col = None
            val_prc_col = None
            for c in df_coupons.columns:
                uc = c.upper()
                if uc in ("VALUE", "VALUE_COUPON", "COUPONVALUE") and not val_col:
                    val_col = c
                if "VALUE_RUB" in uc and not val_rub_col:
                    val_rub_col = c
                if uc in ("VALUEPRC", "VALUE_PRC", "VALUE%") and not val_prc_col:
                    val_prc_col = c
            if not val_col:
                for c in df_coupons.columns:
                    if re.match(r"^VALUE$", c, flags=re.IGNORECASE):
                        val_col = c
                        break
            if not val_rub_col:
                for c in df_coupons.columns:
                    if re.search(r"RUB", c, flags=re.IGNORECASE):
                        if "VALUE" in c.upper() or "RUB" in c.upper():
                            val_rub_col = c
                            break
            if not val_prc_col:
                for c in df_coupons.columns:
                    if re.search(r"PRC|PERC|%|PERCENT", c, flags=re.IGNORECASE):
                        val_prc_col = c
                        break

            chosen_row = None
            if coupon_date:
                for c in possible_coupon_date_cols:
                    try:
                        mask = pd.to_datetime(df_coupons[c], errors="coerce").dt.strftime("%Y-%m-%d") == coupon_date
                        rows = df_coupons[mask]
                        if not rows.empty:
                            chosen_row = rows.iloc[0]
                            break
                    except Exception:
                        pass
            if chosen_row is None:
                for idx in range(len(df_coupons)):
                    row = df_coupons.iloc[idx]
                    has_val = False
                    for colcheck in (val_col, val_rub_col, val_prc_col):
                        try:
                            if colcheck and pd.notnull(row.get(colcheck)):
                                has_val = True
                                break
                        except Exception:
                            pass
                    if has_val:
                        chosen_row = row
                        break

            def norm_str(v):
                if v is None or (isinstance(v, float) and math.isnan(v)):
                    return None
                try:
                    return str(v)
                except Exception:
                    return None

            if chosen_row is not None:
                coupon_value = norm_str(chosen_row.get(val_col)) if val_col else None
                coupon_value_rub = norm_str(chosen_row.get(val_rub_col)) if val_rub_col else None
                coupon_value_prc = norm_str(chosen_row.get(val_prc_col)) if val_prc_col else None

        if (not record_date or not coupon_date or not coupon_currency) and (TQOB_MAP or TQCB_MAP):
            mapping = TQOB_MAP.get(isin) or TQCB_MAP.get(isin)
            if mapping:
                if not record_date:
                    record_date = mapping.get("RECORDDATE") or mapping.get("RECORD_DATE") or mapping.get("RECORD")
                if not coupon_date:
                    coupon_date = mapping.get("COUPONDATE") or mapping.get("COUPON_DATE") or mapping.get("COUPON")
                if not coupon_currency:
                    coupon_currency = mapping.get("FACEUNIT") or mapping.get("FACEUNIT_S") or mapping.get("FACEUNIT")

        def fmt(date):
            if pd.isna(date) or not date:
                return None
            try:
                return pd.to_datetime(date).strftime("%Y-%m-%d")
            except Exception:
                return None

        return {
            "ISIN": isin,
            "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞": emitter_id or "",
            "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞": secname or "",
            "–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è": fmt(maturity_date),
            "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put": fmt(put_date),
            "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call": fmt(call_date),
            "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞": fmt(record_date),
            "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞": fmt(coupon_date),
            "–í–∞–ª—é—Ç–∞ –∫—É–ø–æ–Ω–∞": coupon_currency or "",
            "–ö—É–ø–æ–Ω –≤ –≤–∞–ª—é—Ç–µ": coupon_value or "",
            "–ö—É–ø–æ–Ω –≤ –†—É–±": coupon_value_rub or "",
            "–ö—É–ø–æ–Ω %": coupon_value_prc or "",
        }
    except Exception:
        return {
            "ISIN": isin,
            "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞": "",
            "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞": "",
            "–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è": None,
            "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put": None,
            "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call": None,
            "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞": None,
            "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞": None,
            "–í–∞–ª—é—Ç–∞ –∫—É–ø–æ–Ω–∞": "",
            "–ö—É–ø–æ–Ω –≤ –≤–∞–ª—é—Ç–µ": "",
            "–ö—É–ø–æ–Ω –≤ –†—É–±": "",
            "–ö—É–ø–æ–Ω %": "",
        }


# ---------------------------
# Calendar helpers
# ---------------------------
@st.cache_data(ttl=3600)
def get_bond_schedule(isin: str):
    isin = str(isin).strip().upper()
    emitter_id, secid = fetch_emitter_and_secid(isin)
    maturity_date = put_date = call_date = None
    coupon_events = {}
    facevalue = None

    if secid:
        try:
            url_info = f"https://iss.moex.com/iss/engines/stock/markets/bonds/securities/{secid}.json"
            r = request_get(url_info, timeout=10)
            data_info = r.json()
            rows_info = data_info.get("securities", {}).get("data", [])
            cols_info = data_info.get("securities", {}).get("columns", [])
            if rows_info and cols_info:
                info = dict(zip([c.upper() for c in cols_info], rows_info[0]))
                maturity_date = info.get("MATDATE") or maturity_date
                put_date = info.get("PUTOPTIONDATE") or put_date
                call_date = info.get("CALLOPTIONDATE") or call_date
                if facevalue is None:
                    facevalue = parse_number(info.get("FACEVALUE") or info.get("FACEVALUE_RUB"))
        except Exception:
            pass

    if not maturity_date:
        try:
            url_info_isin = f"https://iss.moex.com/iss/securities/{isin}.json"
            r = request_get(url_info_isin, timeout=10)
            data_info_isin = r.json()
            rows = data_info_isin.get("securities", {}).get("data", [])
            cols = data_info_isin.get("securities", {}).get("columns", [])
            if rows and cols:
                info = dict(zip([c.upper() for c in cols], rows[0]))
                maturity_date = maturity_date or info.get("MATDATE")
                put_date = put_date or info.get("PUTOPTIONDATE") or info.get("PUT_OPTION_DATE")
                call_date = call_date or info.get("CALLOPTIONDATE") or info.get("CALL_OPTION_DATE")
                if facevalue is None:
                    facevalue = parse_number(info.get("FACEVALUE") or info.get("FACEVALUE_RUB"))
        except Exception:
            pass

    def try_fetch_bondization(identifier: str):
        try:
            url_coupons = (
                "https://iss.moex.com/iss/statistics/engines/stock/markets/bonds/"
                f"bondization/{identifier}.json?iss.only=coupons,bondization&iss.meta=off"
            )
            r = request_get(url_coupons, timeout=10)
            data = r.json()
            coupons = data.get("coupons", {}).get("data", [])
            cols = data.get("coupons", {}).get("columns", [])
            bond_rows = data.get("bondization", {}).get("data", [])
            bond_cols = data.get("bondization", {}).get("columns", [])
            bond_info = None
            if bond_rows and bond_cols:
                bond_info = dict(zip([c.upper() for c in bond_cols], bond_rows[0]))
            return coupons, cols, bond_info
        except Exception:
            return None, [], None

    coupons_data = columns_coupons = None
    bond_info = None
    if secid:
        coupons_data, columns_coupons, bond_info = try_fetch_bondization(secid)

    if isin and (not coupons_data or not columns_coupons):
        coupons_data_fallback, columns_coupons_fallback, bond_info_fallback = try_fetch_bondization(isin)
        if coupons_data_fallback and columns_coupons_fallback:
            coupons_data = coupons_data_fallback
            columns_coupons = columns_coupons_fallback
        if not bond_info:
            bond_info = bond_info_fallback or bond_info

    if bond_info:
        for key, value in bond_info.items():
            if key.startswith("FACEVALUE") and value not in (None, "", "None"):
                facevalue = parse_number(value)
                if facevalue is not None:
                    break

    if coupons_data and columns_coupons:
        df_coupons = pd.DataFrame(coupons_data, columns=columns_coupons)
        df_coupons.columns = [c.upper() for c in df_coupons.columns]
        date_cols = [c for c in df_coupons.columns if "COUPON" in c and "DATE" in c]
        if not date_cols:
            date_cols = [c for c in df_coupons.columns if c.endswith("DATE")]

        val_rub_col = next((c for c in df_coupons.columns if "VALUE_RUB" in c), None)
        val_col = next(
            (c for c in df_coupons.columns if c in ("VALUE", "VALUE_COUPON", "COUPONVALUE")),
            None,
        )
        for _, row in df_coupons.iterrows():
            coupon_date = None
            for col in date_cols:
                dt = pd.to_datetime(row.get(col), errors="coerce")
                if pd.notna(dt):
                    coupon_date = dt.strftime("%Y-%m-%d")
                    break
            if not coupon_date:
                continue
            raw_value = row.get(val_rub_col) if val_rub_col else row.get(val_col)
            coupon_value = parse_number(raw_value)
            coupon_events[coupon_date] = coupon_value

    def fmt(date):
        if pd.isna(date) or not date:
            return None
        try:
            return pd.to_datetime(date).strftime("%Y-%m-%d")
        except Exception:
            return None

    return {
        "ISIN": isin,
        "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞": emitter_id or "",
        "–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è": fmt(maturity_date),
        "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put": fmt(put_date),
        "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call": fmt(call_date),
        "–ö—É–ø–æ–Ω—ã": coupon_events,
        "–ù–æ–º–∏–Ω–∞–ª": facevalue,
    }


# ---------------------------
# Parallel fetch with safe progress updates
# ---------------------------
def fetch_isins_parallel(isins, max_workers=10, show_progress=True):
    results = []
    total = len(isins)
    if total == 0:
        return results

    progress_bar = None
    progress_text = None
    if show_progress:
        try:
            progress_bar = st.progress(0)
            progress_text = st.empty()
        except Exception:
            progress_bar = None
            progress_text = None

    completed = 0
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_isin = {executor.submit(get_bond_data, isin): isin for isin in isins}
        for future in as_completed(future_to_isin):
            isin = future_to_isin[future]
            try:
                data = future.result()
            except Exception:
                data = {
                    "ISIN": isin,
                    "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞": "",
                    "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞": "",
                    "–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è": None,
                    "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put": None,
                    "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call": None,
                    "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞": None,
                    "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞": None,
                    "–í–∞–ª—é—Ç–∞ –∫—É–ø–æ–Ω–∞": "",
                    "–ö—É–ø–æ–Ω –≤ –≤–∞–ª—é—Ç–µ": "",
                    "–ö—É–ø–æ–Ω –≤ –†—É–±": "",
                    "–ö—É–ø–æ–Ω %": "",
                }
            results.append(data)
            completed += 1
            if progress_bar:
                try:
                    progress_bar.progress(completed / total)
                except Exception:
                    pass
            if progress_text:
                try:
                    progress_text.text(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {completed}/{total} ISIN")
                except Exception:
                    pass
    try:
        time.sleep(0.12)
    except Exception:
        pass
    return results


# ---------------------------
# Calendar view
# ---------------------------
if st.session_state["active_view"] == "calendar":
    st.subheader("üìÖ –ö–∞–ª–µ–Ω–¥–∞—Ä—å –≤—ã–ø–ª–∞—Ç")
    st.markdown(
        "–í–≤–µ–¥–∏—Ç–µ —Å–ø–∏—Å–æ–∫ –±—É–º–∞–≥ –∏ –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, —á—Ç–æ–±—ã –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –∫–∞–ª–µ–Ω–¥–∞—Ä—å –≤—ã–ø–ª–∞—Ç "
        "(–∫—É–ø–æ–Ω—ã, –ø–æ–≥–∞—à–µ–Ω–∏—è, –æ—Ñ–µ—Ä—Ç—ã) –ø–æ –≤–∞—à–µ–º—É –ø–æ—Ä—Ç—Ñ–µ–ª—é."
    )
    st.markdown("**–†—É—á–Ω–æ–π –≤–≤–æ–¥:** `ISIN | Amount` (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±—É–º–∞–≥).")
    calendar_input = st.text_area(
        "–í–≤–µ–¥–∏—Ç–µ —Å–ø–∏—Å–æ–∫ –±—É–º–∞–≥",
        height=160,
        placeholder="RU000A0JX0J2 | 100\nRU000A0ZZZY1 | 50",
        key="calendar_manual_input",
    )
    if st.button("–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –∫–∞–ª–µ–Ω–¥–∞—Ä—å", key="build_calendar"):
        raw_lines = [line.strip() for line in calendar_input.splitlines() if line.strip()]
        entries = []
        invalid_isins = []
        for line in raw_lines:
            parts = [p.strip() for p in re.split(r"[,.;|/\t]+", line) if p.strip()]
            if not parts:
                continue
            isin = parts[0].upper()
            amount = parse_number(parts[1]) if len(parts) > 1 else 1.0
            if amount is None or amount <= 0:
                amount = 1.0
            if not isin_format_valid(isin) or not isin_checksum_valid(isin):
                invalid_isins.append(isin)
                continue
            entries.append({"ISIN": isin, "Amount": amount})

        if invalid_isins:
            st.warning(
                "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ ISIN –ø—Ä–æ–ø—É—â–µ–Ω—ã: "
                f"{', '.join(invalid_isins[:10])}{'...' if len(invalid_isins) > 10 else ''}"
            )
        if not entries:
            st.error("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö ISIN –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∫–∞–ª–µ–Ω–¥–∞—Ä—è.")
        else:
            max_workers = st.sidebar.slider("–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤ (workers)", 2, 40, 10, key="calendar_workers")
            timeline_data = {}
            all_dates = set()
            with st.spinner("–ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –≤—ã–ø–ª–∞—Ç..."):
                with ThreadPoolExecutor(max_workers=max_workers) as executor:
                    future_to_entry = {
                        executor.submit(get_bond_schedule, entry["ISIN"]): entry for entry in entries
                    }
                    for future in as_completed(future_to_entry):
                        entry = future_to_entry[future]
                        isin = entry["ISIN"]
                        amount = entry["Amount"]
                        try:
                            schedule = future.result()
                        except Exception:
                            schedule = {}
                        row = {}
                        today = datetime.today().date()
                        maturity_date = None
                        for key in ("–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è", "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put", "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call"):
                            event_date = schedule.get(key)
                            if event_date:
                                try:
                                    parsed_date = pd.to_datetime(event_date).date()
                                except Exception:
                                    parsed_date = None
                                if parsed_date and (maturity_date is None or parsed_date < maturity_date):
                                    maturity_date = parsed_date
                                if parsed_date and parsed_date >= today:
                                    all_dates.add(event_date)

                        for date, value in schedule.get("–ö—É–ø–æ–Ω—ã", {}).items():
                            try:
                                coupon_date = pd.to_datetime(date).date()
                            except Exception:
                                continue
                            if coupon_date < today:
                                continue
                            if maturity_date and coupon_date > maturity_date:
                                continue
                            all_dates.add(date)
                            if value is None:
                                continue
                            scaled = value * amount
                            row[date] = row.get(date, 0) + scaled

                        facevalue = schedule.get("–ù–æ–º–∏–Ω–∞–ª")
                        for key in ("–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è", "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put", "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call"):
                            event_date = schedule.get(key)
                            if event_date and facevalue is not None:
                                try:
                                    parsed_date = pd.to_datetime(event_date).date()
                                except Exception:
                                    parsed_date = None
                                if parsed_date and parsed_date >= today:
                                    row[event_date] = row.get(event_date, 0) + facevalue * amount
                        timeline_data[isin] = row

            sorted_dates = sorted(all_dates)
            df_timeline = pd.DataFrame(index=[e["ISIN"] for e in entries], columns=sorted_dates, dtype=float)
            for isin, row in timeline_data.items():
                for date, value in row.items():
                    df_timeline.loc[isin, date] = value
            st.dataframe(df_timeline, use_container_width=True)
    st.stop()

# ---------------------------
# VM view
# ---------------------------
if st.session_state["active_view"] == "vm":
    st.subheader("üßÆ –†–∞—Å—á–µ—Ç VM")
    if "forts_contracts" not in st.session_state:
        with st.spinner("–ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤ FORTS..."):
            try:
                st.session_state["forts_contracts"] = fetch_forts_securities()
            except Exception:
                st.session_state["forts_contracts"] = []
                st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤ FORTS.")
    trade_name = st.text_input("TRADE_NAME (SHORTNAME –±–∏—Ä–∂–∏)", value="", key="vm_trade_name")
    quantity = st.number_input(
        "–ö–æ–ª-–≤–æ (—Ü–µ–ª–æ–µ, –Ω–µ–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ)",
        min_value=0,
        step=1,
        value=0,
        format="%d",
        key="vm_quantity",
    )
    if st.button("–†–∞—Å—Å—á–∏—Ç–∞—Ç—å VM", key="vm_calculate"):
        if not trade_name.strip():
            st.error("–í–≤–µ–¥–∏—Ç–µ TRADE_NAME.")
        else:
            try:
                vm_data = fetch_vm_data(trade_name.strip(), st.session_state.get("forts_contracts"))
                position_vm = vm_data["VM"] * quantity
                st.markdown(f"**–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç:** {vm_data['TRADE_NAME']}")
                st.markdown(f"**SECID:** {vm_data['SECID']}")
                st.markdown(f"**–î–∞—Ç–∞ –∫–ª–∏—Ä–∏–Ω–≥–∞:** {vm_data['TRADEDATE']}")
                st.markdown(
                    f"**–†–∞—Å—á–µ—Ç–Ω–∞—è —Ü–µ–Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫–ª–∏—Ä–∏–Ω–≥–∞:** {vm_data['LAST_SETTLE_PRICE']}"
                )
                st.markdown(f"**–ü–æ—Å–ª–µ–¥–Ω—è—è —Ü–µ–Ω–∞:** {vm_data['TODAY_PRICE']}")
                st.markdown(f"**Multiplier:** {vm_data['MULTIPLIER']}")
                st.markdown(f"**–í–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ä–∂–∞ –∑–∞ –¥–µ–Ω—å:** {vm_data['VM']:.2f}")
                st.markdown(f"**–ú–∞—Ä–∂–∞ –ø–æ–∑–∏—Ü–∏–∏ (VM √ó –ö–æ–ª-–≤–æ):** {position_vm:.2f}")
                usd_rub_data = get_usd_rub_cb_today()
                usd_rub = float(usd_rub_data["usd_rub"])
                limit_sum = (0.05 * vm_data["TODAY_PRICE"] * quantity * usd_rub) + position_vm
                st.markdown(f"**–°—É–º–º–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:** {limit_sum:.2f}")
                st.caption(f"USD/RUB: {usd_rub_data['usd_rub']} –Ω–∞ {usd_rub_data['date']}")
            except Exception as exc:
                st.error(str(exc))
    st.stop()

# ---------------------------
# Sell_stres view
# ---------------------------
if st.session_state["active_view"] == "sell_stres":
    st.subheader("üß© Sell_stres")
    share_tab, bond_tab = st.tabs(["Share", "Bond"])

    with share_tab:
        st.markdown("### Share")
        use_q_from_list = st.checkbox(
            "–í–≤–æ–¥–∏—Ç—å Q –¥–ª—è –∫–∞–∂–¥–æ–≥–æ ISIN (—Ñ–æ—Ä–º–∞—Ç: ISIN | Q)", value=False, key="share_q_per_isin"
        )
        if use_q_from_list:
            isin_q_input = st.text_area(
                "–í–≤–µ–¥–∏—Ç–µ ISIN –∏ Q (–∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞: ISIN | Q)",
                height=160,
                placeholder="RU0009029540 | 33000000000\nRU000A0JX0J2 | 25000000000",
                key="share_isin_q_input",
            )
        else:
            isin_input = st.text_area(
                "–í–≤–µ–¥–∏—Ç–µ –∏–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ ISIN (—á–µ—Ä–µ–∑ Ctrl+V, –ø—Ä–æ–±–µ–ª –∏–ª–∏ –∑–∞–ø—è—Ç—É—é)",
                height=160,
                placeholder="RU0009029540\nRU000A0JX0J2",
                key="share_isin_input",
            )

        c_value = st.number_input(
            "C (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç, 0‚Äì1)",
            min_value=0.0,
            max_value=1.0,
            value=1.0,
            step=0.05,
            format="%.2f",
            key="share_c_value",
        )
        data_from = st.date_input(
            "–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ (data_from)",
            value=datetime(2024, 1, 1).date(),
            key="share_date_from",
        )
        q_max = st.number_input(
            "Q (–º–∞–∫—Å–∏–º—É–º –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–∞)",
            min_value=1,
            value=33_000_000_000,
            step=1_000_000,
            format="%d",
            key="share_q_max",
            disabled=use_q_from_list,
        )
        use_log = st.checkbox("–õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ", value=True, key="share_q_log")
        q_mode = "log" if use_log else "linear"

        if st.button("–†–∞—Å—Å—á–∏—Ç–∞—Ç—å Sell_stres (Share)", key="share_calculate"):
            entries = []
            invalid_isins = []
            if use_q_from_list:
                raw_lines = [line.strip() for line in isin_q_input.splitlines() if line.strip()]
                for line in raw_lines:
                    parts = [p.strip() for p in re.split(r"[|;\t,]+", line) if p.strip()]
                    if not parts:
                        continue
                    isin = parts[0].upper()
                    q_val = parse_number(parts[1]) if len(parts) > 1 else None
                    if not isin_format_valid(isin):
                        invalid_isins.append(isin)
                        continue
                    if q_val is None or q_val <= 0:
                        st.warning(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π Q –¥–ª—è {isin}: {parts[1] if len(parts) > 1 else ''}")
                        continue
                    entries.append({"ISIN": isin, "Q_MAX": int(q_val)})
            else:
                raw_text = isin_input.strip()
                if raw_text:
                    isins = re.split(r"[\s,;]+", raw_text)
                    isins = [i.strip().upper() for i in isins if i.strip()]
                    for isin in isins:
                        if not isin_format_valid(isin):
                            invalid_isins.append(isin)
                            continue
                        entries.append({"ISIN": isin, "Q_MAX": int(q_max)})

            if invalid_isins:
                st.warning(
                    "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –ø–æ —Ñ–æ—Ä–º–∞—Ç—É ISIN –ø—Ä–æ–ø—É—â–µ–Ω—ã: "
                    f"{', '.join(invalid_isins[:10])}{'...' if len(invalid_isins) > 10 else ''}"
                )
            if not entries:
                st.error("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö ISIN –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
            elif len(entries) > ss.MAX_SECURITIES_PER_RUN:
                st.error(
                    f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –±—É–º–∞–≥ –∑–∞ –æ–¥–∏–Ω –∑–∞–ø—É—Å–∫: {len(entries)}. "
                    f"–õ–∏–º–∏—Ç: {ss.MAX_SECURITIES_PER_RUN}."
                )
            else:
                meta_rows = []
                results = {}
                progress_bar = st.progress(0.0)
                with st.spinner("–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º Sell_stres..."):
                    for idx, entry in enumerate(entries, start=1):
                        isin = entry["ISIN"]
                        try:
                            q_vector = ss.build_q_vector(q_mode, entry["Q_MAX"])
                            delta_df, meta = ss.calculate_share_delta_p(
                                request_get=request_get,
                                isin_to_secid=isin_to_secid,
                                isin=isin,
                                c_value=float(c_value),
                                date_from=data_from.strftime("%Y-%m-%d"),
                                q_values=q_vector,
                            )
                            results[isin] = delta_df
                            meta_rows.append(meta)
                        except Exception as exc:
                            st.error(f"{isin}: {exc}")
                        progress_bar.progress(idx / len(entries))

                if results:
                    combined_delta = []
                    show_tables = len(entries) == 1 and not use_q_from_list
                    if show_tables:
                        st.markdown("#### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã ŒîP")
                    for isin, df_delta in results.items():
                        if show_tables:
                            st.markdown(f"**{isin}**")
                            st.dataframe(df_delta, use_container_width=True)
                        combined_delta.append(df_delta.assign(ISIN=isin))

                    combined_delta_df = pd.concat(combined_delta, ignore_index=True)
                    combined_delta_df = combined_delta_df[["ISIN", "Q", "DeltaP"]]
                    combined_delta_bytes = combined_delta_df.to_csv(index=False).encode("utf-8-sig")
                    st.download_button(
                        label="üíæ –°–∫–∞—á–∞—Ç—å –æ–±—â–∏–π ŒîP CSV",
                        data=combined_delta_bytes,
                        file_name="sell_stres_share_deltaP_all.csv",
                        mime="text/csv",
                    )
                    st.download_button(
                        label="üíæ –°–∫–∞—á–∞—Ç—å –æ–±—â–∏–π ŒîP Excel",
                        data=ss.dataframe_to_excel_bytes(combined_delta_df, sheet_name="delta_p"),
                        file_name="sell_stres_share_deltaP_all.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    )

                if meta_rows:
                    meta_df = pd.DataFrame(meta_rows, columns=["ISIN", "T", "Sigma", "MDTV"])
                    if len(entries) == 1:
                        st.markdown("#### Meta_mod")
                        st.dataframe(meta_df, use_container_width=True)
                    meta_bytes = meta_df.to_csv(index=False).encode("utf-8-sig")
                    st.download_button(
                        label="üíæ –°–∫–∞—á–∞—Ç—å –æ–±—â–∏–π Meta_mod CSV",
                        data=meta_bytes,
                        file_name="sell_stres_share_meta_all.csv",
                        mime="text/csv",
                    )
                    st.download_button(
                        label="üíæ –°–∫–∞—á–∞—Ç—å –æ–±—â–∏–π Meta_mod Excel",
                        data=ss.dataframe_to_excel_bytes(meta_df, sheet_name="meta"),
                        file_name="sell_stres_share_meta_all.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    )

    with bond_tab:
        st.markdown("### Bond")
        use_q_from_list_bond = st.checkbox(
            "–í–≤–æ–¥–∏—Ç—å Q –¥–ª—è –∫–∞–∂–¥–æ–≥–æ ISIN (—Ñ–æ—Ä–º–∞—Ç: ISIN | Q)", value=False, key="bond_q_per_isin"
        )
        if use_q_from_list_bond:
            bond_isin_q_input = st.text_area(
                "–í–≤–µ–¥–∏—Ç–µ ISIN –∏ Q (–∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞: ISIN | Q)",
                height=160,
                placeholder="RU000A1095L7 | 300000000\nRU000A0JX0J2 | 150000000",
                key="bond_isin_q_input",
            )
        else:
            bond_isin_input = st.text_area(
                "–í–≤–µ–¥–∏—Ç–µ –∏–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ ISIN (—á–µ—Ä–µ–∑ Ctrl+V, –ø—Ä–æ–±–µ–ª –∏–ª–∏ –∑–∞–ø—è—Ç—É—é)",
                height=160,
                placeholder="RU000A1095L7\nRU000A0JX0J2",
                key="bond_isin_input",
            )

        bond_c_value = st.number_input(
            "C (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–ª–∏—è–Ω–∏—è, 0‚Äì1)",
            min_value=0.0,
            max_value=1.0,
            value=1.0,
            step=0.05,
            format="%.2f",
            key="bond_c_value",
        )
        bond_date_from = st.date_input(
            "–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ (data_from)",
            value=datetime(2023, 1, 1).date(),
            key="bond_date_from",
        )
        bond_q_max = st.number_input(
            "Q_MAX (–º–∞–∫—Å. –æ–±—ä—ë–º –ø—Ä–æ–¥–∞–∂–∏)",
            min_value=1,
            value=300_000_000,
            step=1_000_000,
            format="%d",
            key="bond_q_max",
            disabled=use_q_from_list_bond,
        )
        bond_use_log = st.checkbox(
            "–õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ", value=False, key="bond_q_log"
        )
        bond_q_mode = "log" if bond_use_log else "linear"

        if st.button("–†–∞—Å—Å—á–∏—Ç–∞—Ç—å Sell_stres (Bond)", key="bond_calculate"):
            entries = []
            invalid_isins = []
            if use_q_from_list_bond:
                raw_lines = [line.strip() for line in bond_isin_q_input.splitlines() if line.strip()]
                for line in raw_lines:
                    parts = [p.strip() for p in re.split(r"[|;\t,]+", line) if p.strip()]
                    if not parts:
                        continue
                    isin = parts[0].upper()
                    q_val = parse_number(parts[1]) if len(parts) > 1 else None
                    if not isin_format_valid(isin):
                        invalid_isins.append(isin)
                        continue
                    if q_val is None or q_val <= 0:
                        st.warning(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π Q –¥–ª—è {isin}: {parts[1] if len(parts) > 1 else ''}")
                        continue
                    entries.append({"ISIN": isin, "Q_MAX": int(q_val)})
            else:
                raw_text = bond_isin_input.strip()
                if raw_text:
                    isins = re.split(r"[\s,;]+", raw_text)
                    isins = [i.strip().upper() for i in isins if i.strip()]
                    for isin in isins:
                        if not isin_format_valid(isin):
                            invalid_isins.append(isin)
                            continue
                        entries.append({"ISIN": isin, "Q_MAX": int(bond_q_max)})

            if invalid_isins:
                st.warning(
                    "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –ø–æ —Ñ–æ—Ä–º–∞—Ç—É ISIN –ø—Ä–æ–ø—É—â–µ–Ω—ã: "
                    f"{', '.join(invalid_isins[:10])}{'...' if len(invalid_isins) > 10 else ''}"
                )
            if not entries:
                st.error("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö ISIN –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
            elif len(entries) > ss.MAX_SECURITIES_PER_RUN:
                st.error(
                    f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –±—É–º–∞–≥ –∑–∞ –æ–¥–∏–Ω –∑–∞–ø—É—Å–∫: {len(entries)}. "
                    f"–õ–∏–º–∏—Ç: {ss.MAX_SECURITIES_PER_RUN}."
                )
            else:
                meta_rows = []
                results = {}
                progress_bar = st.progress(0.0)
                with st.spinner("–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º Sell_stres (Bond)..."):
                    for idx, entry in enumerate(entries, start=1):
                        isin = entry["ISIN"]
                        try:
                            delta_df, meta = ss.calculate_bond_delta_p(
                                request_get=request_get,
                                secid=isin,
                                c_value=float(bond_c_value),
                                date_from=bond_date_from.strftime("%Y-%m-%d"),
                                date_to=(datetime.now().date() - timedelta(days=1)).strftime("%Y-%m-%d"),
                                q_mode=bond_q_mode,
                                q_max=entry["Q_MAX"],
                            )
                            results[isin] = delta_df
                            meta_rows.append(meta)
                        except Exception as exc:
                            st.error(f"{isin}: {exc}")
                        progress_bar.progress(idx / len(entries))

                if results:
                    combined_delta = []
                    show_tables = len(entries) == 1 and not use_q_from_list_bond
                    if show_tables:
                        st.markdown("#### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã ŒîP (Bond)")
                    for isin, df_delta in results.items():
                        if show_tables:
                            st.markdown(f"**{isin}**")
                            st.dataframe(df_delta, use_container_width=True)
                        combined_delta.append(df_delta.assign(ISIN=isin))

                    combined_delta_df = pd.concat(combined_delta, ignore_index=True)
                    combined_delta_df = combined_delta_df[["ISIN", "Q", "DeltaP_pct"]]
                    combined_delta_bytes = combined_delta_df.to_csv(index=False).encode("utf-8-sig")
                    st.download_button(
                        label="üíæ –°–∫–∞—á–∞—Ç—å –æ–±—â–∏–π ŒîP CSV (Bond)",
                        data=combined_delta_bytes,
                        file_name="sell_stres_bond_deltaP_all.csv",
                        mime="text/csv",
                    )
                    st.download_button(
                        label="üíæ –°–∫–∞—á–∞—Ç—å –æ–±—â–∏–π ŒîP Excel (Bond)",
                        data=ss.dataframe_to_excel_bytes(combined_delta_df, sheet_name="delta_p"),
                        file_name="sell_stres_bond_deltaP_all.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    )

                if meta_rows:
                    meta_df = pd.DataFrame(
                        meta_rows,
                        columns=["ISIN", "T", "SigmaY", "MDTV", "Price", "YTM", "Dmod"],
                    )
                    if len(entries) == 1:
                        st.markdown("#### Meta_mod (Bond)")
                        st.dataframe(meta_df, use_container_width=True)
                    meta_bytes = meta_df.to_csv(index=False).encode("utf-8-sig")
                    st.download_button(
                        label="üíæ –°–∫–∞—á–∞—Ç—å –æ–±—â–∏–π Meta_mod CSV (Bond)",
                        data=meta_bytes,
                        file_name="sell_stres_bond_meta_all.csv",
                        mime="text/csv",
                    )
                    st.download_button(
                        label="üíæ –°–∫–∞—á–∞—Ç—å –æ–±—â–∏–π Meta_mod Excel (Bond)",
                        data=ss.dataframe_to_excel_bytes(meta_df, sheet_name="meta"),
                        file_name="sell_stres_bond_meta_all.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    )

    st.stop()

# ---------------------------
# REPO duration settings
# ---------------------------
st.subheader("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –†–ï–ü–û")
if "overnight" not in st.session_state:
    st.session_state["overnight"] = False
if "extra_days" not in st.session_state:
    st.session_state["extra_days"] = 2

if st.button("üîÑ –û—á–∏—Å—Ç–∏—Ç—å —Ñ–æ—Ä–º—É"):
    st.session_state["overnight"] = False
    st.session_state["extra_days"] = 2
    st.session_state["results"] = None
    st.session_state["file_loaded"] = False
    st.session_state["last_file_name"] = None
    trigger_rerun()

overnight = st.checkbox("Overnight –†–ï–ü–û", key="overnight")
extra_days_input = st.number_input(
    "–î–Ω–µ–π –†–ï–ü–û:",
    min_value=2,
    max_value=366,
    step=1,
    disabled=st.session_state["overnight"],
    key="extra_days",
)
if st.session_state["overnight"]:
    st.markdown(
        "<span style='color:gray'>–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–Ω–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã –ø—Ä–∏ –≤–∫–ª—é—á–µ–Ω–Ω–æ–º Overnight</span>",
        unsafe_allow_html=True,
    )
days_threshold = 2 if st.session_state["overnight"] else 1 + st.session_state["extra_days"]
st.write(f"–¢–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≥—Ä–∞–Ω–∏—Ü—ã –≤—ã–ø–ª–∞—Ç: {days_threshold} –¥–Ω.")

# ---------------------------
# UI: input tabs
# ---------------------------
st.subheader("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–ª–∏ –≤–≤–æ–¥ ISIN")
tab1, tab2 = st.tabs(["üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª", "‚úçÔ∏è –í–≤–µ—Å—Ç–∏ –≤—Ä—É—á–Ω—É—é"])

with tab1:
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel –∏–ª–∏ CSV —Å –∫–æ–ª–æ–Ω–∫–æ–π ISIN", type=["xlsx", "xls", "csv"])
    st.write("–ü—Ä–∏–º–µ—Ä —à–∞–±–ª–æ–Ω–∞ (—Å–∫–∞—á–∞–π—Ç–µ –∏ –∑–∞–ø–æ–ª–Ω–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É ISIN):")
    sample_csv = "ISIN\nRU000A0JX0J2\nRU000A0ZZZY1\n"
    st.download_button("–°–∫–∞—á–∞—Ç—å —à–∞–±–ª–æ–Ω CSV", data=sample_csv, file_name="template_isin.csv", mime="text/csv")

with tab2:
    isin_input = st.text_area("–í–≤–µ–¥–∏—Ç–µ –∏–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ ISIN (—á–µ—Ä–µ–∑ Ctrl+V, –ø—Ä–æ–±–µ–ª –∏–ª–∏ –∑–∞–ø—è—Ç—É—é)", height=150)
    if st.button("üîç –ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ –≤–≤–µ–¥—ë–Ω–Ω—ã–º ISIN"):
        raw_text = isin_input.strip()
        if raw_text:
            isins = re.split(r"[\s,;]+", raw_text)
            isins = [i.strip().upper() for i in isins if i.strip()]
            invalid_format = [i for i in isins if not isin_format_valid(i)]
            invalid_checksum = [i for i in isins if isin_format_valid(i) and not isin_checksum_valid(i)]
            if invalid_format:
                st.warning(
                    f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –ø–æ —Ñ–æ—Ä–º–∞—Ç—É ISIN –±—É–¥—É—Ç –ø—Ä–æ–ø—É—â–µ–Ω—ã: {', '.join(invalid_format[:10])}"
                    f"{'...' if len(invalid_format) > 10 else ''}"
                )
            if invalid_checksum:
                st.info(
                    f"ISIN —Å –Ω–µ–≤–µ—Ä–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Å—É–º–º–æ–π (–±—É–¥—É—Ç –ø—Ä–æ–ø—É—â–µ–Ω—ã): {', '.join(invalid_checksum[:10])}"
                    f"{'...' if len(invalid_checksum) > 10 else ''}"
                )
            isins = [i for i in isins if isin_format_valid(i) and isin_checksum_valid(i)]
            if not isins:
                st.error("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö ISIN –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
            else:
                max_workers = st.sidebar.slider("–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤ (workers)", 2, 40, 10)
                with st.spinner("–ó–∞–ø—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö..."):
                    results = fetch_isins_parallel(isins, max_workers=max_workers, show_progress=True)
                st.session_state["results"] = pd.DataFrame(results)
                st.success("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã!")

# ---------------------------
# File upload handling
# ---------------------------
if uploaded_file:
    if not st.session_state["file_loaded"] or uploaded_file.name != st.session_state["last_file_name"]:
        st.session_state["file_loaded"] = True
        st.session_state["last_file_name"] = uploaded_file.name

        df = safe_read_filelike(uploaded_file)
        if df.empty:
            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –∏–ª–∏ —Ñ–∞–π–ª –ø—É—Å—Ç.")
            st.stop()
        df.columns = [c.strip().upper() for c in df.columns]

        if "ISIN" not in df.columns:
            candidates = []
            for c in df.columns:
                try:
                    if df[c].dropna().astype(str).str.match(r"^[A-Z]{2}[A-Z0-9]{9}[0-9]$").any():
                        candidates.append(c)
                except Exception:
                    continue
            if len(candidates) == 1:
                df.rename(columns={candidates[0]: "ISIN"}, inplace=True)
                st.info(f"–ê–≤—Ç–æ-–¥–µ—Ç–µ–∫—Ç: –∫–æ–ª–æ–Ω–∫–∞ '{candidates[0]}' –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –∫–∞–∫ ISIN")
            else:
                st.error("‚ùå –í —Ñ–∞–π–ª–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∫–æ–ª–æ–Ω–∫–∞ 'ISIN' –∏–ª–∏ –æ–¥–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ —Å ISIN-–ø–æ–¥–æ–±–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏.")
                st.stop()

        isins = df["ISIN"].dropna().unique().tolist()
        isins = [str(x).strip().upper() for x in isins if str(x).strip()]
        invalid_fmt = [i for i in isins if not isin_format_valid(i)]
        invalid_chk = [i for i in isins if isin_format_valid(i) and not isin_checksum_valid(i)]
        if invalid_fmt:
            st.warning(
                f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –ø–æ —Ñ–æ—Ä–º–∞—Ç—É ISIN –ø—Ä–æ–ø—É—â–µ–Ω—ã: {', '.join(invalid_fmt[:10])}"
                f"{'...' if len(invalid_fmt) > 10 else ''}"
            )
        if invalid_chk:
            st.info(
                f"ISIN —Å –Ω–µ–≤–µ—Ä–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Å—É–º–º–æ–π –ø—Ä–æ–ø—É—â–µ–Ω—ã: {', '.join(invalid_chk[:10])}"
                f"{'...' if len(invalid_chk) > 10 else ''}"
            )
        isins = [i for i in isins if isin_format_valid(i) and isin_checksum_valid(i)]

        st.write(f"–ù–∞–π–¥–µ–Ω–æ {len(isins)} –≤–∞–ª–∏–¥–Ω—ã—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö ISIN –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
        if isins:
            max_workers = st.sidebar.slider("–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤ (workers)", 2, 40, 10)
            with st.spinner("–ó–∞–ø—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ñ–∞–π–ª—É..."):
                results = fetch_isins_parallel(isins, max_workers=max_workers, show_progress=True)
            st.session_state["results"] = pd.DataFrame(results)
            st.success("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞!")

# ---------------------------
# Load emitter reference (optional)
# ---------------------------
@st.cache_data(ttl=3600)
def fetch_emitter_names():
    url = "https://raw.githubusercontent.com/mainarkler/Bond_date/refs/heads/main/Pifagr_name_with_emitter.csv"
    try:
        df_emitters = pd.read_csv(url, dtype=str)
        df_emitters.columns = [c.strip() for c in df_emitters.columns]
        return df_emitters
    except Exception:
        return pd.DataFrame(columns=["Issuer", "EMITTER_ID"])


df_emitters = fetch_emitter_names()

# ---------------------------
# Styling helper
# ---------------------------
def style_df(row):
    if pd.isna(row.get("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞")) or row.get("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞") in [None, "", "None"]:
        return ["background-color: DimGray; color: white"] * len(row)
    today = datetime.today().date()
    danger_threshold = today + timedelta(days=days_threshold)
    key_dates = ["–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è", "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put", "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call", "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞", "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞"]
    colors = ["" for _ in row]
    for i, col in enumerate(row.index):
        if col in key_dates and pd.notnull(row[col]):
            try:
                d = pd.to_datetime(row[col]).date()
                if d <= danger_threshold:
                    colors[i] = "background-color: Chocolate"
            except Exception:
                pass
    if any(c == "background-color: Chocolate" for c in colors):
        colors = ["background-color: SandyBrown" if c == "" else c for c in colors]
    return colors

# ---------------------------
# Show results (table + export) with filter for orange-highlighted rows
# ---------------------------
if st.session_state["results"] is not None:
    df_res = st.session_state["results"].copy()

    if "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞" in df_res.columns and not df_emitters.empty:
        try:
            df_res = df_res.merge(df_emitters, how="left", left_on="–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞", right_on="EMITTER_ID")
            df_res["–≠–º–∏—Ç–µ–Ω—Ç"] = df_res.get("Issuer")
            df_res.drop(columns=["Issuer", "EMITTER_ID"], inplace=True, errors="ignore")
            cols = df_res.columns.tolist()
            if "–≠–º–∏—Ç–µ–Ω—Ç" in cols and "–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞" in cols:
                cols.remove("–≠–º–∏—Ç–µ–Ω—Ç")
                idx = cols.index("–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞")
                cols.insert(idx + 1, "–≠–º–∏—Ç–µ–Ω—Ç")
                df_res = df_res[cols]
            st.session_state["results"] = df_res
        except Exception:
            pass
    else:
        st.warning("‚ö†Ô∏è –í –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ '–ö–æ–¥ —ç–º–∏—Ç–µ–Ω—Ç–∞' ‚Äî –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–º –ø—Ä–æ–ø—É—â–µ–Ω–æ.")

    st.markdown(f"**–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π:** {len(df_res)}")

    today = datetime.today().date()
    danger_threshold = today + timedelta(days=days_threshold)
    key_dates = ["–î–∞—Ç–∞ –ø–æ–≥–∞—à–µ–Ω–∏—è", "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Put", "–î–∞—Ç–∞ –æ—Ñ–µ—Ä—Ç—ã Call", "–î–∞—Ç–∞ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –∫—É–ø–æ–Ω–∞", "–î–∞—Ç–∞ –∫—É–ø–æ–Ω–∞"]

    mask_any = pd.Series(False, index=df_res.index)
    for col in key_dates:
        if col in df_res.columns:
            try:
                s = pd.to_datetime(df_res[col], errors="coerce").dt.date
                mask_any = mask_any | (s <= danger_threshold)
            except Exception:
                pass

    only_orange = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –±—É–º–∞–≥–∏ —Å –æ—Ç—Å–µ—á–∫–æ–π –≤ –ø–µ—Ä–∏–æ–¥–µ", value=False)
    if only_orange:
        df_show = df_res[mask_any].copy()
        st.markdown(f"**–ü–æ–∫–∞–∑–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π —Å –æ—Ç—Å–µ—á–∫–æ–π:** {len(df_show)}")
        if df_show.empty:
            st.info("–ù–µ—Ç –±—É–º–∞–≥, –ø–æ–ø–∞–¥–∞—é—â–∏—Ö –ø–æ–¥ –∫—Ä–∏—Ç–µ—Ä–∏–π (–æ—Ç—Å–µ—á–∫–∏).")
    else:
        df_show = df_res

    st.dataframe(df_show.style.apply(style_df, axis=1), use_container_width=True)

    def to_excel_bytes(df: pd.DataFrame):
        output = BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            df.to_excel(writer, index=False, sheet_name="–î–∞–Ω–Ω—ã–µ")
        return output.getvalue()

    def to_csv_bytes(df: pd.DataFrame):
        return df.to_csv(index=False).encode("utf-8-sig")

    st.download_button(
        label="üíæ –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç (Excel)",
        data=to_excel_bytes(df_show),
        file_name="bond_data.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )
    st.download_button(
        label="üíæ –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç (CSV)",
        data=to_csv_bytes(df_show),
        file_name="bond_data.csv",
        mime="text/csv",
    )
else:
    st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –∏–ª–∏ –≤–≤–µ–¥–∏—Ç–µ ISIN-—ã –≤—Ä—É—á–Ω—É—é.")
